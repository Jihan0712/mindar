<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>INRL AR Viewer</title>

    <!-- A-Frame + MindAR -->
    <script src="https://aframe.io/releases/1.5.0/aframe.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mind-ar@1.2.5/dist/mindar-image-aframe.prod.js"></script>

    <!-- Supabase Client -->
    <script type="module">
      import { createClient } from "https://esm.sh/@supabase/supabase-js@2";

      const SUPABASE_URL = "https://vleqrpqfjkcazeowczjy.supabase.co";
      const SUPABASE_ANON_KEY =
        "sb_publishable_yB6MBOTVLquZgR4X6yqhTQ_0wBFkhrZ";

      const supabase = createClient(SUPABASE_URL, SUPABASE_ANON_KEY);

      async function loadActiveTarget() {
        console.log("Loading active target from Supabase...");

        const { data, error } = await supabase
          .from("targets")
          .select("*")
          .eq("is_active", true)
          .single();

        if (error || !data) {
          console.error("‚ùå No active target found or DB error:", error);
          document.body.innerHTML =
            "<h2 style='text-align:center; color:red;'>‚ùå No active target found in database.</h2>";
          return null;
        }

        console.log("Active target loaded:", data);
        return data;
      }

      document.addEventListener("DOMContentLoaded", async () => {
        const activeTarget = await loadActiveTarget();
        if (!activeTarget) return;

        const mindUrl = activeTarget.mindUrl;
        const videoUrl = activeTarget.videoUrl;

        const scene = document.querySelector("a-scene");
        const plane = document.querySelector("#video-plane");
        const target = document.querySelector("#target");

        // Create and load video
        const video = document.createElement("video");
        video.src = videoUrl;
        video.crossOrigin = "anonymous";
        video.loop = true;
        video.playsInline = true;
        video.muted = true;
        video.preload = "auto";

        // ‚úÖ Create an offscreen 1:1 canvas to letterbox the video
        const canvas = document.createElement("canvas");
        const ctx = canvas.getContext("2d");
        const texture = new THREE.CanvasTexture(canvas);
        plane.getObject3D("mesh").material.map = texture;
        plane.getObject3D("mesh").material.needsUpdate = true;

        // ‚úÖ Handle video metadata for sizing
        video.addEventListener("loadedmetadata", () => {
          const size = 512; // 1:1 square canvas
          canvas.width = size;
          canvas.height = size;

          const videoAspect = video.videoWidth / video.videoHeight;
          let drawWidth, drawHeight, offsetX, offsetY;

          // Fit video inside square, add black borders where needed
          if (videoAspect > 1) {
            // Wider video ‚Äî black bars top/bottom
            drawWidth = size;
            drawHeight = size / videoAspect;
            offsetX = 0;
            offsetY = (size - drawHeight) / 2;
          } else {
            // Taller video ‚Äî black bars left/right
            drawHeight = size;
            drawWidth = size * videoAspect;
            offsetX = (size - drawWidth) / 2;
            offsetY = 0;
          }

          // Draw continuously to canvas
          const drawFrame = () => {
            ctx.fillStyle = "black";
            ctx.fillRect(0, 0, size, size);
            ctx.drawImage(video, offsetX, offsetY, drawWidth, drawHeight);
            texture.needsUpdate = true;
            requestAnimationFrame(drawFrame);
          };
          drawFrame();

          console.log("üé¨ Video aspect:", videoAspect.toFixed(2));
        });

        // ‚úÖ Handle video playback and target tracking
        document.body.addEventListener(
          "click",
          () => {
            video.muted = false;
            video.play().catch((err) => {
              console.warn("Autoplay blocked:", err);
            });
          },
          { once: true }
        );

        target.addEventListener("targetFound", () => {
          console.log("üéØ Target found!");
          video.play();
        });

        target.addEventListener("targetLost", () => {
          console.log("üëÄ Target lost!");
          video.pause();
        });

        // ‚úÖ Set MindAR target dynamically
        scene.setAttribute("mindar-image", `imageTargetSrc: ${mindUrl};`);
      });
    </script>
  </head>

  <body style="margin: 0; overflow: hidden; background: transparent;">
    <a-scene
      mindar-image="imageTargetSrc: ./placeholder.mind;"
      color-space="sRGB"
      renderer="colorManagement: true, physicallyCorrectLights, alpha: true"
      vr-mode-ui="enabled: false"
      device-orientation-permission-ui="enabled: false"
      embedded
      style="width: 100%; height: 100%;"
    >
      <a-camera position="0 0 0" look-controls="enabled: false"></a-camera>

      <a-entity id="target" mindar-image-target="targetIndex: 0">
        <!-- 1:1 video surface -->
        <a-plane
          id="video-plane"
          position="0 0 0"
          width="1"
          height="1"
          rotation="0 0 0"
          material="shader: flat; transparent: true;"
        ></a-plane>
      </a-entity>
    </a-scene>
  </body>
</html>
