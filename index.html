<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>INRL AR Viewer (Stabilized)</title>

    <!-- A-Frame + MindAR -->
    <script src="https://aframe.io/releases/1.5.0/aframe.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mind-ar@1.2.5/dist/mindar-image-aframe.prod.js"></script>

    <style>
      #start-screen {
        position: fixed;
        inset: 0;
        background: linear-gradient(135deg, #0f172a, #1e293b);
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        color: white;
        font-family: "Poppins", sans-serif;
        z-index: 9999;
        cursor: pointer;
        text-align: center;
        transition: opacity 0.5s ease;
      }

      #start-screen.hidden {
        opacity: 0;
        pointer-events: none;
      }

      #start-screen h1 {
        font-size: 2rem;
        margin-bottom: 0.5rem;
        animation: pulse 1.5s infinite;
      }

      #start-screen p {
        font-size: 1.1rem;
        opacity: 0.8;
      }

      @keyframes pulse {
        0% { transform: scale(1); opacity: 1; }
        50% { transform: scale(1.1); opacity: 0.8; }
        100% { transform: scale(1); opacity: 1; }
      }
    </style>

    <!-- Supabase Client -->
    <script type="module">
      import { createClient } from "https://esm.sh/@supabase/supabase-js@2";

  const SUPABASE_URL = "https://cxcbgrhqujgrrmkqcewv.supabase.co";
  const SUPABASE_ANON_KEY = "sb_publishable_kdk75aMwV6efd8Fcs1AsoA_a905uRWO";
      const supabase = createClient(SUPABASE_URL, SUPABASE_ANON_KEY);

      async function loadActiveTarget() {
        console.log("üì° Loading active target from Supabase...");
        const params = new URLSearchParams(window.location.search);
        const brand = (params.get('brand') || '').trim();
        const product = (params.get('product') || '').trim();

        // Build query: be permissive when only product is provided (match any brand),
        // but when no params are provided default to the global bucket (brand IS NULL and product IS NULL).
        let q = supabase
          .from('targets')
          .select('*')
          .eq('is_active', true);

        const noParams = !brand && !product;

        // Case-insensitive matches to be forgiving on mobile keyboards/URLs
        if (brand) q = q.ilike('brand', brand);
        if (product) q = q.ilike('product', product);

        if (noParams) {
          // Original behavior: load the global active target when no params are provided
          q = q.is('brand', null).is('product', null);
        }

        // Be resilient if multiple rows match (e.g., duplicates). Take most recent.
        q = q.order('updated_at', { ascending: false }).limit(1);

        const { data, error } = await q;

        if (error || !Array.isArray(data) || data.length === 0) {
          console.error("‚ùå No active target found or query failed:", error);
          const message = error?.message || 'No active target found for this brand/product.';
          document.body.innerHTML =
            `<div style="padding:16px;text-align:center;color:#b91c1c;">
               <h2 style='margin-bottom:8px;'>‚ùå ${message}</h2>
               <div style="font-size:12px;color:#6b7280;">Tip: Ensure the target is marked active and that public SELECT is allowed by RLS for active targets.</div>
             </div>`;
          return null;
        }

        const row = data[0];
        console.log("‚úÖ Active target loaded:", row);
        return row;
      }

      document.addEventListener("DOMContentLoaded", async () => {
        const tOverallStart = performance.now();
        const activeTarget = await loadActiveTarget();
        console.log(`timing: fetched active target in ${Math.round(performance.now()-tOverallStart)}ms`);
        if (!activeTarget) return;

        const mindUrl = activeTarget.mindurl;
        const videoUrl = activeTarget.videourl;

        const scene = document.querySelector("a-scene");
        const aframeVideoAsset = document.querySelector("#card");
        const planeEl = document.querySelector("#video-plane");
        const target = document.querySelector("#target");

        // Prefetch the .mind file to warm the browser cache - MindAR will still
        // request it, but this can reduce latency on initial load.
        (async () => {
          try {
            const t = performance.now();
            await fetch(mindUrl, { method: 'GET', mode: 'cors', cache: 'force-cache' });
            console.log(`timing: prefetched .mind in ${Math.round(performance.now()-t)}ms`);
          } catch (e) {
            console.warn('Could not prefetch .mind (non-fatal):', e);
          }
        })();

        scene.setAttribute("mindar-image", `imageTargetSrc: ${mindUrl};`);

        // Set video attributes early so the browser can begin fetching metadata as soon
        // as possible. We still wait for loadedmetadata before starting the draw loop.
        try { aframeVideoAsset.setAttribute('crossorigin', 'anonymous'); } catch (e) {}
        aframeVideoAsset.src = videoUrl;
        aframeVideoAsset.loop = true;
        aframeVideoAsset.muted = true;
        aframeVideoAsset.playsInline = true;
        aframeVideoAsset.preload = "auto";

        // Wait until mesh is ready. More robust: listen for both 'loaded' (A-Frame primitive)
        // and 'model-loaded' events, and poll for a longer window before giving up.
        function whenPlaneMeshReady(cb) {
          try {
            const existingMesh = planeEl.getObject3D && planeEl.getObject3D("mesh");
            if (existingMesh) {
              console.log('whenPlaneMeshReady: mesh already present');
              return cb(existingMesh);
            }

            const onLoaded = () => {
              const m = planeEl.getObject3D && planeEl.getObject3D('mesh');
              if (m) {
                cleanup();
                return cb(m);
              }
            };

            const onModelLoaded = () => {
              const m = planeEl.getObject3D && planeEl.getObject3D('mesh');
              if (m) {
                cleanup();
                return cb(m);
              }
            };

            planeEl.addEventListener('loaded', onLoaded);
            planeEl.addEventListener('model-loaded', onModelLoaded);

            let tries = 0;
            const iv = setInterval(() => {
              const m = planeEl.getObject3D && planeEl.getObject3D('mesh');
              if (m) {
                cleanup();
                console.log('whenPlaneMeshReady: mesh found via polling');
                return cb(m);
              }
              tries++;
              if (tries > 100) { // ~10s
                console.warn('whenPlaneMeshReady: Could not find plane mesh after polling');
                cleanup();
              }
            }, 100);

            function cleanup() {
              planeEl.removeEventListener('loaded', onLoaded);
              planeEl.removeEventListener('model-loaded', onModelLoaded);
              clearInterval(iv);
            }
          } catch (err) {
            console.error('whenPlaneMeshReady error:', err);
          }
        }

        // Helper: infer target aspect ratio from stored marker image URL if available
        async function getTargetAspectFromImage(active) {
          const url = active?.imageurl;
          if (!url) return null;
          try {
            const img = new Image();
            img.crossOrigin = 'anonymous';
            const p = new Promise((resolve, reject) => {
              img.onload = () => resolve(img);
              img.onerror = reject;
            });
            img.src = url;
            const loaded = await p;
            const w = loaded.naturalWidth || 0;
            const h = loaded.naturalHeight || 0;
            if (w > 0 && h > 0) return w / h; // width/height
          } catch (e) {
            console.warn('Could not infer target aspect from imageurl:', e);
          }
          return null;
        }

        // Decide whether borders are needed and which type (letterbox = top/bottom, pillarbox = left/right)
        function decideBorder(targetAspect, videoAspect, tol = 0.02) {
          const tAspect = targetAspect && Number.isFinite(targetAspect) && targetAspect > 0 ? targetAspect : 1;
          const vAspect = Number.isFinite(videoAspect) && videoAspect > 0 ? videoAspect : 1;
          if (Math.abs(tAspect - vAspect) <= tol) return { same: true, mode: 'none' };
          if (vAspect > tAspect) return { same: false, mode: 'letterbox' };
          return { same: false, mode: 'pillarbox' };
        }

        // Size the plane to match the marker's real aspect (width=1 unit, height=1/targetAspect)
        const targetAspect = await getTargetAspectFromImage(activeTarget) || 1;
        const planeWidthUnits = 1;
        const planeHeightUnits = 1 / targetAspect;

        whenPlaneMeshReady((mesh) => {
          // Make the main plane act as the black border (fills the marker)
          planeEl.setAttribute("width", planeWidthUnits);
          planeEl.setAttribute("height", planeHeightUnits);
          try { planeEl.setAttribute('material', 'shader: flat; color: #000;'); } catch(e) {}

          // Create (or reuse) an inner video plane that will display the <video> element directly.
          // This avoids drawing the video into a canvas (and thus avoids any canvas CORS/taint issues).
          let inner = target.querySelector('#video-inner-plane');
          if (!inner) {
            inner = document.createElement('a-plane');
            inner.setAttribute('id', 'video-inner-plane');
            inner.setAttribute('src', '#card');
            inner.setAttribute('position', '0 0 0.001');
            inner.setAttribute('rotation', '0 0 0');
            inner.setAttribute('material', 'shader: flat; transparent: false; color: #fff;');
            inner.setAttribute('visible', 'false');
            target.appendChild(inner);
          }

          // Size the inner plane to preserve the video's aspect ratio and fit inside the marker.
          function sizeInnerPlane() {
            const vw = aframeVideoAsset.videoWidth;
            const vh = aframeVideoAsset.videoHeight;
            if (!vw || !vh) return;
            const videoAspect = vw / vh;

            const markerW = planeWidthUnits;
            const markerH = planeHeightUnits;
            let videoUnitW, videoUnitH;
            if (videoAspect > (markerW / markerH)) {
              videoUnitW = markerW;
              videoUnitH = markerW / videoAspect;
            } else {
              videoUnitH = markerH;
              videoUnitW = markerH * videoAspect;
            }

            inner.setAttribute('width', videoUnitW);
            inner.setAttribute('height', videoUnitH);
            inner.setAttribute('visible', 'true');
            try { planeEl.setAttribute('visible', 'true'); } catch(e) {}
          }

          // Wait for video metadata so we can read natural dimensions.
          if (aframeVideoAsset.readyState >= 1) sizeInnerPlane();
          else aframeVideoAsset.addEventListener('loadedmetadata', sizeInnerPlane, { once: true });
        });

        // start when found 
        const startScreen = document.getElementById("start-screen");
        let userInteracted = false;
        startScreen.addEventListener("click", () => {
          startScreen.classList.add("hidden");
          // user tapping
          userInteracted = true;
          aframeVideoAsset.muted = false;
          // do not call play
        }, { once: true });

        // Stabilizer - smooth movement/rotation
        const SMOOTHING_FACTOR = 0.05;
        let lastPosition = new THREE.Vector3();
        let lastRotation = new THREE.Euler();

        scene.addEventListener("renderstart", () => {
          const obj = target.object3D;
          const tick = () => {
            lastPosition.lerp(obj.position, SMOOTHING_FACTOR);
            obj.position.copy(lastPosition);
            lastRotation.x += (obj.rotation.x - lastRotation.x) * SMOOTHING_FACTOR;
            lastRotation.y += (obj.rotation.y - lastRotation.y) * SMOOTHING_FACTOR;
            lastRotation.z += (obj.rotation.z - lastRotation.z) * SMOOTHING_FACTOR;
            obj.rotation.copy(lastRotation);
            requestAnimationFrame(tick);
          };
          tick();
        });

        target.addEventListener("targetFound", () => {
          console.log("üéØ Target found ‚Äî play video");
          // User interaction check
          if (userInteracted) {
            aframeVideoAsset.play().catch((e) => console.warn("play error:", e));
          } else {
            // Try to play (checking if blocked)
            aframeVideoAsset.play().catch((e) => {
              console.warn("play blocked (no user gesture):", e);
              const prompt = document.createElement('div');
              prompt.id = 'play-prompt';
              prompt.style.cssText = 'position:fixed;bottom:20px;left:50%;transform:translateX(-50%);background:#111;color:#fff;padding:8px 12px;border-radius:8px;z-index:10001;cursor:pointer;';
              prompt.textContent = 'Tap to enable video playback';
              document.body.appendChild(prompt);
              prompt.addEventListener('click', () => {
                userInteracted = true;
                aframeVideoAsset.muted = false;
                aframeVideoAsset.play().catch(() => {});
                prompt.remove();
              }, { once: true });
            });
          }
        });

        target.addEventListener("targetLost", () => {
          console.log("üëÄ Target lost ‚Äî pause video");
          aframeVideoAsset.pause();
        });
      });
    </script>
  </head>

  <body>
    <!-- Tap-to-Start overlay -->
    <div id="start-screen">
      <h1>Initializing INRL...</h1>
      <p>Enable audio and begin your AR experience</p>
    </div>

    <a-scene
      color-space="sRGB"
      renderer="colorManagement: true, physicallyCorrectLights"
      vr-mode-ui="enabled: false"
      device-orientation-permission-ui="enabled: false">

      <a-assets>
        <video id="card" preload="auto" crossorigin="anonymous" playsinline webkit-playsinline></video>
      </a-assets>

      <a-camera position="0 0 0" look-controls="enabled: false"></a-camera>

      <a-entity id="target" mindar-image-target="targetIndex: 0">
        <a-plane
          id="video-plane"
          src="#card"
          position="0 0 0"
          width="1"
          height="1"
          rotation="0 0 0"
          material="shader: flat; transparent: false; color: #fff;">
        </a-plane>
      </a-entity>
    </a-scene>
  </body>
</html>